#!/usr/bin/env python3
"""
ä¸»ç•Œé¢æ¨¡å— - è´Ÿè´£Streamlitç•Œé¢å’Œç”¨æˆ·äº¤äº’
"""
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from matplotlib.dates import DateFormatter
import matplotlib.patches as patches
import seaborn as sns
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# Import custom modules
from data_fetcher import get_futures_data, get_supported_futures_symbols, validate_futures_symbol
from data_processor import calculate_technical_indicators, validate_data_quality, get_feature_importance_data, create_features_targets
from model_trainer import train_complete_workflow, plot_model_comparison, plot_prediction_scatter, plot_confusion_matrix, evaluate_model_performance, get_feature_importance_from_model
from model_predictor import predict_future_trend, plot_prediction_results, generate_prediction_report, create_prediction_summary_table

# Set matplotlib style
plt.style.use('seaborn-v0_8')
sns.set_theme(style="whitegrid")
plt.rcParams['figure.figsize'] = (10, 6)
plt.rcParams['axes.unicode_minus'] = False

# Initialize session state
if 'data' not in st.session_state:
    st.session_state.data = None
if 'processed_data' not in st.session_state:
    st.session_state.processed_data = None
if 'training_results' not in st.session_state:
    st.session_state.training_results = {}
if 'best_model' not in st.session_state:
    st.session_state.best_model = None


def plot_matplotlib_candlestick(df, title="Candlestick Chart"):
    """ä½¿ç”¨Matplotlibç»˜åˆ¶Kçº¿å›¾"""
    try:
        # è®¾ç½®å­—ä½“é…ç½®
        plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False

        # ç¡®ä¿æ•°æ®æŒ‰æ—¥æœŸæ’åº
        df = df.sort_index().reset_index()
        df = df.rename(columns={'index': 'date'})

        # # é™åˆ¶æ˜¾ç¤ºæœ€è¿‘200å¤©æ•°æ®ä»¥æé«˜æ€§èƒ½
        # if len(df) > 200:
        #     df = df.tail(200)
        #     st.info(f"æ•°æ®é‡è¾ƒå¤§ï¼Œä»…æ˜¾ç¤ºæœ€è¿‘200å¤©æ•°æ®")

        # åˆ›å»ºå›¾è¡¨
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10),
                                       gridspec_kw={'height_ratios': [3, 1]},
                                       sharex=True)
        fig.suptitle(title, fontsize=16, fontweight='bold')

        # è½¬æ¢æ—¥æœŸæ ¼å¼
        dates = mdates.date2num(df['date'])

        # ç»˜åˆ¶Kçº¿
        for i in range(len(df)):
            date = dates[i]
            open_price = df.iloc[i]['open']
            high_price = df.iloc[i]['high']
            low_price = df.iloc[i]['low']
            close_price = df.iloc[i]['close']

            # è®¾ç½®é¢œè‰²ï¼šçº¢è‰²ä¸Šæ¶¨ï¼Œç»¿è‰²ä¸‹è·Œï¼ˆä¸­å›½æœŸè´§å¸‚åœºæƒ¯ä¾‹ï¼‰
            color = 'red' if close_price >= open_price else 'green'

            # ç»˜åˆ¶ä¸Šä¸‹å½±çº¿
            ax1.plot([date, date], [low_price, high_price], color=color, linewidth=1)

            # ç»˜åˆ¶å®ä½“
            height = abs(close_price - open_price)
            bottom = min(open_price, close_price)

            rect = patches.Rectangle((date - 0.3, bottom), 0.6, height,
                                   facecolor=color, edgecolor=color, alpha=0.8)
            ax1.add_patch(rect)

        # ç»˜åˆ¶ç§»åŠ¨å¹³å‡çº¿
        if 'MA5' in df.columns and not df['MA5'].isnull().all():
            ax1.plot(dates, df['MA5'], 'b-', linewidth=1.5, label='MA5', alpha=0.8)

        if 'MA10' in df.columns and not df['MA10'].isnull().all():
            ax1.plot(dates, df['MA10'], 'orange', linewidth=1.5, label='MA10', alpha=0.8)

        if 'MA20' in df.columns and not df['MA20'].isnull().all():
            ax1.plot(dates, df['MA20'], 'purple', linewidth=1.5, label='MA20', alpha=0.8)

        # è®¾ç½®ä»·æ ¼å›¾è¡¨æ ¼å¼
        ax1.set_title('Price Trend', fontsize=14)
        ax1.set_ylabel('Price', fontsize=12)
        ax1.grid(True, alpha=0.3)
        # åªæœ‰å½“å­˜åœ¨å›¾ä¾‹é¡¹æ—¶æ‰æ˜¾ç¤ºå›¾ä¾‹
        if ax1.get_legend_handles_labels()[0]:  # æ£€æŸ¥æ˜¯å¦æœ‰å›¾ä¾‹é¡¹
            ax1.legend()

        # ç»˜åˆ¶æˆäº¤é‡
        for i in range(len(df)):
            date = dates[i]
            volume = df.iloc[i]['volume']
            close_price = df.iloc[i]['close']
            open_price = df.iloc[i]['open']

            # æˆäº¤é‡é¢œè‰²å¯¹åº”Kçº¿
            color = 'red' if close_price >= open_price else 'green'

            ax2.bar(date, volume, width=0.6, color=color, alpha=0.8)

        # è®¾ç½®æˆäº¤é‡å›¾è¡¨æ ¼å¼
        ax2.set_title('Volume', fontsize=14)
        ax2.set_ylabel('Volume', fontsize=12)
        ax2.grid(True, alpha=0.3)

        # è®¾ç½®xè½´æ—¥æœŸæ ¼å¼
        ax2.xaxis.set_major_formatter(DateFormatter('%Y-%m-%d'))
        ax2.xaxis.set_major_locator(mdates.AutoDateLocator())
        plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45)

        # è°ƒæ•´å¸ƒå±€
        plt.tight_layout()

        return fig

    except Exception as e:
        st.error(f"Matplotlibå›¾è¡¨ç»˜åˆ¶é”™è¯¯: {str(e)}")
        return None


def render_sidebar():
    """æ¸²æŸ“ä¾§è¾¹æ """
    st.sidebar.title("âš™ï¸ å‚æ•°é…ç½®")

    # è‡ªå®šä¹‰æœŸè´§ä»£ç è¾“å…¥
    symbol = st.sidebar.text_input("è¾“å…¥è‡ªå®šä¹‰æœŸè´§ä»£ç ", value="CF0")

    st.sidebar.markdown(f"**å½“å‰é€‰æ‹©**: {symbol}")

    # æ—¶é—´èŒƒå›´é€‰æ‹©
    st.sidebar.subheader("ğŸ“… æ—¶é—´èŒƒå›´")
    use_date_range = st.sidebar.checkbox("è‡ªå®šä¹‰æ—¥æœŸèŒƒå›´", value=False)

    if use_date_range:
        start_date = st.sidebar.date_input("å¼€å§‹æ—¥æœŸ", datetime.now() - timedelta(days=90))
        end_date = st.sidebar.date_input("ç»“æŸæ—¥æœŸ", datetime.now())
        start_date_str = start_date.strftime('%Y-%m-%d')
        end_date_str = end_date.strftime('%Y-%m-%d')
        days = None
    else:
        days = st.sidebar.slider("è·å–æœ€è¿‘å¤©æ•°", min_value=30, max_value=365, value=90)
        start_date_str = None
        end_date_str = None

    # é¢„æµ‹å‚æ•°
    st.sidebar.subheader("ğŸ”® é¢„æµ‹å‚æ•°")
    historical_days = st.sidebar.slider("å†å²æ•°æ®å¤©æ•°", min_value=5, max_value=30, value=7)
    prediction_days = st.sidebar.slider("é¢„æµ‹å¤©æ•°", min_value=1, max_value=15, value=1)
    train_size = st.sidebar.slider("è®­ç»ƒé›†æ¯”ä¾‹", min_value=0.6, max_value=0.9, value=0.7)

    # é¢„æµ‹ç±»å‹
    task_type = st.sidebar.radio(
        "é¢„æµ‹ç±»å‹",
        options=["åˆ†ç±»é¢„æµ‹","å›å½’é¢„æµ‹"],
        index=0,
        help="åˆ†ç±»é¢„æµ‹ï¼šé¢„æµ‹æ¶¨è·Œæ–¹å‘\nå›å½’é¢„æµ‹ï¼šé¢„æµ‹ä»·æ ¼å˜åŒ–ç™¾åˆ†æ¯”"
    )
    task_type_value = 'regression' if task_type == "å›å½’é¢„æµ‹" else 'classification'

    return {
        'symbol': symbol,
        'days': days,
        'start_date': start_date_str,
        'end_date': end_date_str,
        'historical_days': historical_days,
        'prediction_days': prediction_days,
        'train_size': train_size,
        'task_type': task_type_value
    }


def render_data_preview_tab(df):
    """æ¸²æŸ“æ•°æ®é¢„è§ˆæ ‡ç­¾é¡µ"""
    st.header("ğŸ“Š åŸå§‹æ•°æ®")

    if df is not None and len(df) > 0:
        # æ·»åŠ æ¶¨è·Œå¹…åˆ—
        df_with_change = df.copy()
        df_with_change['æ¶¨è·Œå¹…(%)'] = df_with_change['close'].pct_change() * 100
        # ç¬¬ä¸€è¡Œçš„æ¶¨è·Œå¹…è®¾ä¸º0
        df_with_change.loc[df_with_change.index[0], 'æ¶¨è·Œå¹…(%)'] = 0

        # æ•°æ®åŸºæœ¬ä¿¡æ¯
        st.subheader("æ•°æ®åŸºæœ¬ä¿¡æ¯")
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("æ•°æ®æ¡æ•°", len(df_with_change))
        with col2:
            st.metric("å¼€å§‹æ—¥æœŸ", df_with_change.index.min().strftime('%Y-%m-%d'))
        with col3:
            st.metric("ç»“æŸæ—¥æœŸ", df_with_change.index.max().strftime('%Y-%m-%d'))
        with col4:
            latest_price = df_with_change['close'].iloc[-1]
            prev_price = df_with_change['close'].iloc[-2] if len(df_with_change) > 1 else latest_price
            price_change = latest_price - prev_price
            price_change_pct = (price_change / prev_price) * 100 if prev_price != 0 else 0
            st.metric("æœ€æ–°ä»·æ ¼", f"{latest_price:.2f}", f"{price_change_pct:+.2f}%")

        # æ•°æ®é¢„è§ˆ
        st.subheader("æ•°æ®é¢„è§ˆï¼ˆåŒ…å«æ¶¨è·Œå¹…ï¼‰")
        st.dataframe(df_with_change)

        # æ¶¨è·Œå¹…ç»Ÿè®¡
        st.subheader("æ¶¨è·Œå¹…ç»Ÿè®¡")
        price_changes = df_with_change['æ¶¨è·Œå¹…(%)'].dropna()  # ç§»é™¤ç¬¬ä¸€è¡Œçš„NaN

        col1, col2, col3, col4 = st.columns(4)
        with col1:
            positive_days = (price_changes > 0).sum()
            st.metric("ä¸Šæ¶¨å¤©æ•°", f"{positive_days}")
        with col2:
            negative_days = (price_changes < 0).sum()
            st.metric("ä¸‹è·Œå¤©æ•°", f"{negative_days}")
        with col3:
            flat_days = (price_changes == 0).sum()
            st.metric("å¹³ç›˜å¤©æ•°", f"{flat_days}")
        with col4:
            max_change = price_changes.max()
            min_change = price_changes.min()
            st.metric("æœ€å¤§æ¶¨è·Œå¹…", f"{max_change:+.2f}% / {min_change:+.2f}%")

        # æ¶¨è·Œå¹…åˆ†å¸ƒå›¾è¡¨
        st.subheader("æ¶¨è·Œå¹…åˆ†å¸ƒå›¾è¡¨")
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

        # ç›´æ–¹å›¾
        n_bins = 30
        _, bins, patches = ax1.hist(price_changes, bins=n_bins, alpha=0.7,
                                   color='skyblue', edgecolor='black')

        # æ ¹æ®æ¶¨è·Œå¹…è®¾ç½®é¢œè‰²
        for i, patch in enumerate(patches):
            if bins[i] >= 0:
                patch.set_facecolor('#44BB44')  # ä¸Šæ¶¨ç»¿è‰²
            else:
                patch.set_facecolor('#FF4444')  # ä¸‹è·Œçº¢è‰²

        ax1.axvline(x=0, color='black', linestyle='--', alpha=0.5)
        ax1.axvline(x=price_changes.mean(), color='orange', linestyle='--',
                   alpha=0.7, label=f'Mean: {price_changes.mean():.2f}%')

        ax1.set_xlabel('Change (%)')
        ax1.set_ylabel('Frequency')
        ax1.set_title('Historical Price Change Distribution')
        ax1.legend()
        ax1.grid(True, alpha=0.3)

        # è¶‹åŠ¿åˆ†å¸ƒç›´æ–¹å›¾
        try:
            # åˆ›å»ºåˆ†ç±»ç‰¹å¾ç”¨äºè¶‹åŠ¿åˆ†æ
            df_processed = calculate_technical_indicators(df_with_change)
            X, y = create_features_targets(df_processed,
                                         historical_days=7,
                                         prediction_days=3,
                                         task_type='classification')

            if len(y) > 0:
                # ç»Ÿè®¡å„ç±»åˆ«æ•°é‡
                trend_counts = y.value_counts().sort_index()
                trend_names = {0: "Down ğŸ“‰", 1: "Sideways â¡ï¸", 2: "Up ğŸ“ˆ"}
                # åˆ›å»ºæ˜ å°„åçš„æ ‡ç­¾
                trend_labels = [trend_names.get(i, f"Class {i}") for i in trend_counts.index]

                # ç»˜åˆ¶æŸ±çŠ¶å›¾
                colors = ['#FF4444', '#FFA500', '#44BB44']  # çº¢ã€æ©™ã€ç»¿
                bars = ax2.bar(trend_labels, trend_counts.values.astype(float),
                             color=colors[:len(trend_labels)], alpha=0.7)

                # æ·»åŠ æ•°å€¼æ ‡ç­¾
                for bar in bars:
                    height = bar.get_height()
                    ax2.text(bar.get_x() + bar.get_width()/2., height + max(trend_counts.values)*0.01,
                           f'{int(height)}', ha='center', va='bottom', fontweight='bold')

                ax2.set_xlabel('Trend Type')
                ax2.set_ylabel('Frequency')
                ax2.set_title('Trend Distribution Histogram')
                ax2.grid(True, alpha=0.3, axis='y')

                # æ·»åŠ ç™¾åˆ†æ¯”æ ‡ç­¾
                total_samples = len(y)
                for i, count in enumerate(trend_counts.values):
                    percentage = (count / total_samples) * 100
                    ax2.text(i, count/2, f'{percentage:.1f}%', ha='center', va='center',
                           color='white', fontweight='bold')
            else:
                # å¦‚æœæ— æ³•åˆ›å»ºåˆ†ç±»ç‰¹å¾ï¼Œæ˜¾ç¤ºæ›¿ä»£ä¿¡æ¯
                ax2.text(0.5, 0.5, 'Insufficient data for trend analysis',
                        ha='center', va='center', transform=ax2.transAxes, fontsize=12)
                ax2.set_title('Trend Distribution (Not Available)')
                ax2.set_xlabel('Trend Type')
                ax2.set_ylabel('Frequency')

        except Exception as e:
            # å¦‚æœè¶‹åŠ¿åˆ†æå¤±è´¥ï¼Œæ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
            ax2.text(0.5, 0.5, f'Trend analysis failed:\n{str(e)}',
                    ha='center', va='center', transform=ax2.transAxes, fontsize=10)
            ax2.set_title('Trend Distribution (Error)')
            ax2.set_xlabel('Trend Type')
            ax2.set_ylabel('Frequency')

        plt.tight_layout()
        st.pyplot(fig)
        plt.close()

        # # è¯¦ç»†æ¶¨è·Œå¹…ç»Ÿè®¡è¡¨æ ¼
        # st.subheader("è¯¦ç»†æ¶¨è·Œå¹…ç»Ÿè®¡")
        # stats_data = {
        #     'æ€»äº¤æ˜“æ—¥': len(price_changes),
        #     'å¹³å‡æ¶¨è·Œå¹…(%)': f"{price_changes.mean():.3f}",
        #     'æœ€å¤§æ¶¨å¹…(%)': f"{price_changes.max():.3f}",
        #     'æœ€å¤§è·Œå¹…(%)': f"{price_changes.min():.3f}",
        #     'æ ‡å‡†å·®(%)': f"{price_changes.std():.3f}",
        #     'ä¸­ä½æ•°(%)': f"{np.median(price_changes):.3f}",
        #     'ååº¦': f"{pd.Series(price_changes).skew():.3f}",
        #     'å³°åº¦': f"{pd.Series(price_changes).kurtosis():.3f}"
        # }

        # # è½¬æ¢ä¸ºDataFrameå¹¶æ¨ªå‘æ˜¾ç¤º
        # stats_df = pd.DataFrame([stats_data]).T
        # stats_df.columns = ['æ•°å€¼']
        # st.dataframe(stats_df, width='content')

        # æ•°æ®è´¨é‡æŠ¥å‘Š
        st.subheader("æ•°æ®è´¨é‡æŠ¥å‘Š")
        quality_info = validate_data_quality(df)

        col1, col2 = st.columns(2)
        with col1:
            st.write(f"**å®Œæ•´æ€§**: {quality_info['completeness']:.1f}%")
            st.write(f"**ç¼ºå¤±å€¼**: {quality_info['missing_values']}")
            st.write(f"**é‡å¤è¡Œ**: {quality_info['duplicate_rows']}")

        with col2:
            st.write(f"**æ€»è¡Œæ•°**: {quality_info['total_rows']}")
            st.write(f"**æ•°å€¼åˆ—æ•°**: {len(quality_info['numeric_columns'])}")
            st.write(f"**æ€»åˆ—æ•°**: {len(quality_info['columns'])}")

    else:
        st.warning("æš‚æ— æ•°æ®ï¼Œè¯·å…ˆè·å–æœŸè´§æ•°æ®")


def render_price_chart_tab(df):
    """æ¸²æŸ“ä»·æ ¼å›¾è¡¨æ ‡ç­¾é¡µ"""
    st.header("ğŸ“ˆ ä»·æ ¼èµ°åŠ¿å›¾")

    if df is not None and len(df) > 0:
        # ç»˜åˆ¶Kçº¿å›¾
        fig = plot_matplotlib_candlestick(df, f"Futures Candlestick Chart")
        if fig:
            st.pyplot(fig)
            plt.close()

        # æ•°æ®æ‘˜è¦
        st.subheader("æ•°æ®æ‘˜è¦")
        latest_data = df.iloc[-1]
        first_data = df.iloc[0]

        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("å¼€ç›˜ä»·", f"{latest_data['open']:.2f}")
        with col2:
            st.metric("æ”¶ç›˜ä»·", f"{latest_data['close']:.2f}")
        with col3:
            st.metric("æœ€é«˜ä»·", f"{latest_data['high']:.2f}")
        with col4:
            st.metric("æœ€ä½ä»·", f"{latest_data['low']:.2f}")

        # æœŸé—´æ¶¨è·Œå¹…
        total_change = (latest_data['close'] - first_data['close']) / first_data['close'] * 100
        st.metric("æœŸé—´æ¶¨è·Œå¹…", f"{total_change:+.2f}%")

    else:
        st.warning("æš‚æ— æ•°æ®ï¼Œè¯·å…ˆè·å–æœŸè´§æ•°æ®")


def render_feature_engineering_tab(df, params):
    """æ¸²æŸ“ç‰¹å¾å·¥ç¨‹æ ‡ç­¾é¡µ"""
    st.header("ğŸ”§ ç‰¹å¾å·¥ç¨‹")

    if df is not None and len(df) > 0:
        # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
        processed_df = calculate_technical_indicators(df)
        st.session_state.processed_data = processed_df

        # åˆ›å»ºç‰¹å¾å’Œç›®æ ‡å˜é‡ç”¨äºåˆ†å¸ƒåˆ†æ
        X, y = create_features_targets(processed_df, historical_days=params['historical_days'],
                                     prediction_days=params['prediction_days'], task_type=params['task_type'])

        # æ˜¾ç¤ºæ‰€æœ‰è®­ç»ƒç‰¹å¾
        st.subheader("ğŸ¯ All Training Features")

        if len(X) > 0:
            # æ˜¾ç¤ºç‰¹å¾ç»´åº¦ä¿¡æ¯
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("æ€»ç‰¹å¾æ•°", f"{X.shape[1]}")
            with col2:
                st.metric("è®­ç»ƒæ ·æœ¬æ•°", f"{len(X)}")
            with col3:
                st.metric("å†å²å¤©æ•°", f"{params['historical_days']}")

            # åˆ›å»ºç‰¹å¾ç±»å‹åˆ†ç»„
            feature_groups = {}
            base_features = set()

            # æŒ‰åŸºç¡€ç‰¹å¾åˆ†ç»„
            for feature_name in X.columns:
                if '_day_' in feature_name:
                    base_feature = feature_name.split('_day_')[0]
                    base_features.add(base_feature)
                    if base_feature not in feature_groups:
                        feature_groups[base_feature] = []
                    day_num = feature_name.split('_day_')[1]
                    feature_groups[base_feature].append((int(day_num), feature_name))
                else:
                    # å¦‚æœä¸æ˜¯æ—¶é—´åºåˆ—ç‰¹å¾ï¼Œå•ç‹¬å½’ç±»
                    if 'Other' not in feature_groups:
                        feature_groups['Other'] = []
                    feature_groups['Other'].append((0, feature_name))

            # æŒ‰å¤©æ•°å­—æ®µæ’åº
            for base_feature in feature_groups:
                feature_groups[base_feature].sort(key=lambda x: x[0])

            # æ˜¾ç¤ºç‰¹å¾åˆ†ç»„ä¿¡æ¯
            st.subheader("ğŸ“Š Feature Categories")
            categories_info = []
            for base_feature, features_list in feature_groups.items():
                categories_info.append({
                    'Feature Category': base_feature,
                    'Count': len(features_list),
                    'Days': f"Day 1 to Day {max([day for day, _ in features_list])}" if len(features_list) > 1 else "Single Day"
                })

            categories_df = pd.DataFrame(categories_info)
            st.dataframe(categories_df, width='content')

            # æ˜¾ç¤ºæœ€æ–°æ ·æœ¬çš„æ‰€æœ‰ç‰¹å¾å€¼
            st.subheader("ğŸ” Latest Training Sample (All Features)")
            st.write(f"Showing the most recent training sample with all {X.shape[1]} features:")

            # è·å–æœ€æ–°æ ·æœ¬å¹¶è½¬ç½®æ˜¾ç¤º
            latest_sample = X.iloc[-1:].T
            latest_sample.columns = ['Latest Value']

            # æŒ‰åŸºç¡€ç‰¹å¾åˆ†ç»„æ˜¾ç¤º
            with st.expander("ğŸ“‹ View Features by Category", expanded=True):
                for base_feature, features_list in feature_groups.items():
                    st.write(f"**{base_feature}** ({len(features_list)} features)")

                    # æå–è¯¥ç±»åˆ«çš„ç‰¹å¾
                    category_features = [feature_name for _, feature_name in features_list]
                    category_data = latest_sample.loc[category_features]

                    # æ ¼å¼åŒ–æ˜¾ç¤º
                    display_data = category_data.copy()
                    display_data['Feature Name'] = display_data.index
                    display_data = display_data.reset_index(drop=True)
                    display_data.columns = ['Latest Value', 'Feature Name']
                    display_data = display_data[['Feature Name', 'Latest Value']]

                    # æ·»åŠ ç‰¹å¾è¯´æ˜
                    feature_descriptions = {
                        # åŸºç¡€ä»·æ ¼æ•°æ®
                        'open': 'Opening Price',
                        'high': 'Highest Price',
                        'low': 'Lowest Price',
                        'close': 'Closing Price',
                        'volume': 'Volume',

                        # ç§»åŠ¨å¹³å‡çº¿
                        'MA5': '5-Day Moving Average',
                        'MA10': '10-Day Moving Average',
                        'MA20': '20-Day Moving Average',

                        # åŠ¨é‡æŒ‡æ ‡
                        'RSI': 'Relative Strength Index (14)',
                        'MACD': 'MACD Line (12-26)',
                        'Signal': 'MACD Signal Line (9)',
                        'Histogram': 'MACD Histogram',

                        # å¸ƒæ—å¸¦
                        'BB_upper': 'Bollinger Band Upper (20Â±2Ïƒ)',
                        'BB_middle': 'Bollinger Band Middle (20)',
                        'BB_lower': 'Bollinger Band Lower (20-2Ïƒ)',

                        # ä»·æ ¼å˜åŒ–ç‡
                        'price_change': '1-Day Price Change %',
                        'price_change_3d': '3-Day Price Change %',
                        'price_change_5d': '5-Day Price Change %',

                        # æˆäº¤é‡æŒ‡æ ‡
                        'volume_MA5': '5-Day Volume MA',
                        'volume_MA10': '10-Day Volume MA',
                        'volume_ratio': 'Current/5D Volume Ratio',

                        # ä»·æ ¼å½¢æ€æŒ‡æ ‡
                        'price_position': 'Price Position in Daily Range',
                        'volatility': '10-Day Price Volatility',

                        # === æ–°å¢æŠ€æœ¯æŒ‡æ ‡ ===
                        # è¶…ä¹°è¶…å–æŒ‡æ ‡
                        'Williams_R': 'Williams %R (14)',
                        'K_value': 'Stochastic %K (9)',
                        'D_value': 'Stochastic %D (9)',
                        'J_value': 'Stochastic %J (9)',

                        # åŠ¨é‡å’Œè¶‹åŠ¿æŒ‡æ ‡
                        'momentum': '10-Day Momentum',
                        'price_acceleration': 'Price Acceleration (2nd derivative)',

                        # æˆäº¤é‡å’Œä»·æ ¼æŒ‡æ ‡
                        'VWAP': 'Volume Weighted Average Price (20)',
                        'ATR': 'Average True Range (14)',

                        # å…¶ä»–æŒ‡æ ‡
                        'CCI': 'Commodity Channel Index (20)',
                        'OBV': 'On Balance Volume (cumulative)'
                    }

                    display_data['Description'] = display_data['Feature Name'].apply(
                        lambda x: feature_descriptions.get(x.split('_day_')[0], 'Unknown Feature')
                    )

                    # æ˜¾ç¤ºæ•°æ®è¡¨æ ¼
                    st.dataframe(display_data, width='stretch', use_container_width=True)

                    # æ·»åŠ åˆ†éš”çº¿
                    if base_feature != list(feature_groups.keys())[-1]:
                        st.markdown("---")

            # ç‰¹å¾ç»Ÿè®¡ä¿¡æ¯
            st.subheader("ğŸ“ˆ Feature Statistics Summary")
            feature_stats = X.describe().T
            feature_stats = feature_stats[['mean', 'std', 'min', 'max', 'count']]
            feature_stats.columns = ['Mean', 'Std Dev', 'Min', 'Max', 'Count']

            # æŒ‰åŸºç¡€ç‰¹å¾åˆ†ç»„æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            with st.expander("ğŸ“Š Detailed Feature Statistics", expanded=False):
                for base_feature, features_list in feature_groups.items():
                    st.write(f"**{base_feature} Statistics**")
                    category_features = [feature_name for _, feature_name in features_list]
                    category_stats = feature_stats.loc[category_features]
                    st.dataframe(category_stats, width='stretch')
                    st.markdown("---")

        else:
            st.warning("No training features available. Please check data processing steps.")

    else:
        st.warning("No data available, please fetch futures data first")


def render_model_training_tab(params):
    """æ¸²æŸ“æ¨¡å‹è®­ç»ƒæ ‡ç­¾é¡µ"""
    st.header("ğŸ¤– æ¨¡å‹è®­ç»ƒä¸é¢„æµ‹")

    if st.session_state.processed_data is None:
        st.warning("è¯·å…ˆå®Œæˆæ•°æ®å¤„ç†æ­¥éª¤")
        return

    # è®­ç»ƒæŒ‰é’®
    if st.button("ğŸš€ å¼€å§‹è®­ç»ƒæ¨¡å‹", type="primary"):
        with st.spinner("æ­£åœ¨è®­ç»ƒæ¨¡å‹..."):
            try:
                results = train_complete_workflow(
                    st.session_state.processed_data,
                    historical_days=params['historical_days'],
                    prediction_days=params['prediction_days'],
                    task_type=params['task_type'],
                    train_size=params['train_size']
                )

                if results:
                    st.session_state.training_results = results
                    st.session_state.best_model = results['best_model']
                    st.success("æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
                else:
                    st.error("æ¨¡å‹è®­ç»ƒå¤±è´¥")
            except Exception as e:
                st.error(f"è®­ç»ƒè¿‡ç¨‹å‡ºé”™: {str(e)}")

    # æ˜¾ç¤ºè®­ç»ƒç»“æœ
    if st.session_state.training_results:
        results = st.session_state.training_results

        # æ¨¡å‹æ€§èƒ½å¯¹æ¯”
        st.subheader("ğŸ“Š æ¨¡å‹æ€§èƒ½å¯¹æ¯”")
        performance_df = evaluate_model_performance(results['results'], results['task_type'])
        if not performance_df.empty:
            st.dataframe(performance_df, width='stretch')

        # é¢„æµ‹ç»“æœå¯è§†åŒ– - ä½¿ç”¨æœ€ä½³æ¨¡å‹
        if results['task_type'] == 'regression':
            st.subheader("ğŸ“ˆ é¢„æµ‹æ•£ç‚¹å›¾ (æœ€ä½³æ¨¡å‹)")
            best_model_name = results['best_model']
            if best_model_name and best_model_name in results['results']:
                result = results['results'][best_model_name]
                if result is not None:
                    fig = plot_prediction_scatter(
                        results['y_test'], result['predictions'], best_model_name
                    )
                    if fig:
                        st.pyplot(fig)
                        plt.close()
                    else:
                        st.info("æœ€ä½³æ¨¡å‹æ•£ç‚¹å›¾ç”Ÿæˆå¤±è´¥")
            else:
                st.warning("æ— æ³•æ‰¾åˆ°æœ€ä½³æ¨¡å‹çš„é¢„æµ‹ç»“æœ")
        else:
            st.subheader("ğŸ¯ æ··æ·†çŸ©é˜µ (æœ€ä½³æ¨¡å‹)")
            best_model_name = results['best_model']
            if best_model_name and best_model_name in results['results']:
                result = results['results'][best_model_name]
                if result is not None:
                    metrics = result['metrics']
                    fig = plot_confusion_matrix(
                        metrics['confusion_matrix'],
                        metrics['class_names'],
                        best_model_name
                    )
                    if fig:
                        st.pyplot(fig)
                        plt.close()
                    else:
                        st.info("æœ€ä½³æ¨¡å‹æ··æ·†çŸ©é˜µç”Ÿæˆå¤±è´¥")
            else:
                st.warning("æ— æ³•æ‰¾åˆ°æœ€ä½³æ¨¡å‹çš„é¢„æµ‹ç»“æœ")


def render_feature_importance_tab():
    """æ¸²æŸ“ç‰¹å¾é‡è¦æ€§æ ‡ç­¾é¡µ"""
    st.header("ğŸ“Š ç‰¹å¾é‡è¦æ€§åˆ†æ")

    if not st.session_state.training_results:
        st.warning("è¯·å…ˆå®Œæˆæ¨¡å‹è®­ç»ƒ")
        return

    results = st.session_state.training_results

    if results['best_model'] is not None:
        # è·å–æœ€ä½³æ¨¡å‹çš„å®é™…æ¨¡å‹å¯¹è±¡
        best_model_name = results['best_model']
        if best_model_name in results['results'] and results['results'][best_model_name] is not None:
            actual_model = results['results'][best_model_name]['model']
            feature_names = list(results['X'].columns)
            importance_df = get_feature_importance_from_model(
                actual_model,
                feature_names,
                results['X_test'],
                results['y_test']
            )

            if not importance_df.empty:
                # æŒ‰åŸºç¡€ç‰¹å¾åˆ†ç»„
                importance_grouped = get_feature_importance_data(results['X'], importance_df['Importance'].to_numpy())

                st.subheader("ç‰¹å¾é‡è¦æ€§æ’å (Top 20)")
                if len(importance_grouped) > 0:
                    st.dataframe(importance_grouped.head(20), width='stretch')

                # # ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§å›¾
                # fig, ax = plt.subplots(figsize=(12, 8))
                # top_features = importance_grouped.head(15)
                # bars = ax.barh(range(len(top_features)), top_features['Importance'])
                # ax.set_yticks(range(len(top_features)))
                # ax.set_yticklabels(top_features['Feature'])
                # ax.set_xlabel('Importance')
                # ax.set_title('Feature Importance Analysis')
                # ax.grid(True, alpha=0.3)

                ## æ·»åŠ æ•°å€¼æ ‡ç­¾
                # for i, bar in enumerate(bars):
                #     width = bar.get_width()
                #     ax.text(width + 0.001, bar.get_y() + bar.get_height()/2,
                #            f'{width:.3f}', ha='left', va='center')

                # plt.tight_layout()
                # st.pyplot(fig)
                # plt.close()
            else:
                st.warning("æ— æ³•è·å–ç‰¹å¾é‡è¦æ€§ä¿¡æ¯")
        else:
            st.warning("è¯¥æ¨¡å‹ä¸æ”¯æŒç‰¹å¾é‡è¦æ€§åˆ†æ")
    else:
        st.warning("æ²¡æœ‰å¯ç”¨çš„æœ€ä½³æ¨¡å‹")


def render_future_prediction_tab(params):
    """æ¸²æŸ“æœªæ¥é¢„æµ‹æ ‡ç­¾é¡µ"""
    st.header("ğŸ”® æœªæ¥é¢„æµ‹æŠ¥å‘Š")

    if st.session_state.best_model is None:
        st.warning("è¯·å…ˆå®Œæˆæ¨¡å‹è®­ç»ƒ")
        return

    if st.session_state.processed_data is None:
        st.warning("è¯·å…ˆå®Œæˆæ•°æ®å¤„ç†")
        return

    # é¢„æµ‹å‚æ•°æ§åˆ¶
    st.subheader("é¢„æµ‹å‚æ•°è®¾ç½®")
    col1, col2, col3 = st.columns(3)

    with col1:
        pred_days = st.slider("é¢„æµ‹å¤©æ•°", min_value=1, max_value=15, value=params['prediction_days'])
    with col2:
        show_confidence = st.checkbox("æ˜¾ç¤ºç½®ä¿¡åŒºé—´", value=True)
    # with col3:
    #     generate_report = st.checkbox("ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š", value=True)

    # ç”Ÿæˆé¢„æµ‹æŒ‰é’®
    if st.button("ğŸ”® ç”Ÿæˆæœªæ¥é¢„æµ‹", type="primary"):
        with st.spinner("æ­£åœ¨ç”Ÿæˆæœªæ¥é¢„æµ‹..."):
            try:
                prediction_results = predict_future_trend(
                    st.session_state.best_model,
                    st.session_state.processed_data,
                    historical_days=params['historical_days'],
                    prediction_days=pred_days,
                    task_type=params['task_type']
                )

                if prediction_results:
                    st.session_state.prediction_results = prediction_results
                    st.success("é¢„æµ‹ç”Ÿæˆå®Œæˆï¼")
                else:
                    st.error("é¢„æµ‹ç”Ÿæˆå¤±è´¥")
            except Exception as e:
                st.error(f"é¢„æµ‹è¿‡ç¨‹å‡ºé”™: {str(e)}")

    # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
    if 'prediction_results' in st.session_state and st.session_state.prediction_results:
        pred_results = st.session_state.prediction_results

        # é¢„æµ‹æ‘˜è¦
        st.subheader("ğŸ“‹ é¢„æµ‹æ‘˜è¦")
        current_price = pred_results['current_price']

        if pred_results['task_type'] == 'regression':
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("å½“å‰ä»·æ ¼", f"{current_price:.2f}")
            with col2:
                final_prediction = pred_results['predictions'][-1]
                final_price = current_price * (1 + final_prediction / 100)
                st.metric("æœŸæœ«ä»·æ ¼", f"{final_price:.2f}")
            with col3:
                total_change = final_prediction
                st.metric("é¢„æµ‹æ€»å˜åŒ–", f"{total_change:+.2f}%")
            with col4:
                if pred_results['predictions']:
                    confidence = min(0.9, max(0.1, 1 - np.std(pred_results['predictions']) / (np.mean(np.abs(pred_results['predictions'])) + 1e-6)))
                    st.metric("é¢„æµ‹ç½®ä¿¡åº¦", f"{confidence:.2f}")
        else:
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("å½“å‰ä»·æ ¼", f"{current_price:.2f}")
            with col2:
                trend_names = {0: "Down", 1: "Sideways", 2: "Up"}
                most_common = max(set(pred_results['predictions']), key=pred_results['predictions'].count)
                st.metric("ä¸»è¦è¶‹åŠ¿", trend_names.get(most_common, "æœªçŸ¥"))
            with col3:
                if pred_results['predictions']:
                    confidence = min(0.9, max(0.1, 1 - np.std(pred_results['predictions']) / (np.mean(np.abs(pred_results['predictions'])) + 1e-6)))
                    st.metric("é¢„æµ‹ç½®ä¿¡åº¦", f"{confidence:.2f}")

        # é¢„æµ‹æ•°æ®è¡¨
        st.subheader("ğŸ“Š è¯¦ç»†é¢„æµ‹æ•°æ®")
        summary_df = create_prediction_summary_table(pred_results)
        if not summary_df.empty:
            st.dataframe(summary_df, width='stretch')

        # å¯è§†åŒ–é¢„æµ‹ç»“æœ
        st.subheader("ğŸ“ˆ é¢„æµ‹è¶‹åŠ¿å›¾")
        fig = plot_prediction_results(
            pred_results['historical_data'],
            pred_results['predictions'],
            pred_results['dates'],
            pred_results['task_type'],
            show_confidence
        )
        if fig:
            st.pyplot(fig)
            plt.close()

def main():
    """ä¸»å‡½æ•°"""
    # è®¾ç½®é¡µé¢é…ç½®
    st.set_page_config(
        page_title="æœŸè´§è¡Œæƒ…é¢„æµ‹å¹³å°",
        page_icon="ğŸ“ˆ",
        layout="wide",
        initial_sidebar_state="expanded"
    )

    # é¡µé¢æ ‡é¢˜
    st.title("ğŸš€ æœŸè´§è¡Œæƒ…é¢„æµ‹å¹³å°")
    st.markdown("---")

    # æ¸²æŸ“ä¾§è¾¹æ 
    params = render_sidebar()

    # è·å–æ•°æ®æŒ‰é’®
    if st.sidebar.button("ğŸ“Š è·å–æœŸè´§æ•°æ®", type="primary"):
        with st.spinner("æ­£åœ¨è·å–æœŸè´§æ•°æ®..."):
            try:
                # éªŒè¯æœŸè´§ä»£ç 
                if not validate_futures_symbol(params['symbol']):
                    st.error(f"æœŸè´§ä»£ç  {params['symbol']} å¯èƒ½æ— æ•ˆï¼Œè¯·æ£€æŸ¥åé‡è¯•")
                else:
                    data = get_futures_data(
                        symbol=params['symbol'],
                        days=params['days'],
                        start_date=params['start_date'],
                        end_date=params['end_date']
                    )
                    if data is not None and len(data) > 0:
                        st.session_state.data = data
                        st.success(f"æˆåŠŸè·å– {params['symbol']} çš„æœŸè´§æ•°æ®")
                    else:
                        st.error("è·å–æœŸè´§æ•°æ®å¤±è´¥")
            except Exception as e:
                st.error(f"æ•°æ®è·å–å‡ºé”™: {str(e)}")

    # ä¸»æ ‡ç­¾é¡µ
    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
        "ğŸ“Š åŸå§‹æ•°æ®",
        "ğŸ“ˆ ä»·æ ¼èµ°åŠ¿å›¾",
        "ğŸ”§ ç‰¹å¾å·¥ç¨‹",
        "ğŸ¤– æ¨¡å‹è®­ç»ƒä¸é¢„æµ‹",
        "ğŸ“Š ç‰¹å¾é‡è¦æ€§",
        "ğŸ”® æœªæ¥é¢„æµ‹æŠ¥å‘Š"
    ])

    with tab1:
        render_data_preview_tab(st.session_state.data)

    with tab2:
        render_price_chart_tab(st.session_state.data)

    with tab3:
        render_feature_engineering_tab(st.session_state.data, params)

    with tab4:
        render_model_training_tab(params)

    with tab5:
        render_feature_importance_tab()

    with tab6:
        render_future_prediction_tab(params)

    # é¡µè„š
    st.markdown("---")
    st.markdown(
        """
        <div style='text-align: center; color: gray; font-size: 12px;'>
        âš ï¸ æŠ•èµ„é£é™©æç¤ºï¼šæœ¬å¹³å°é¢„æµ‹ç»“æœä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚æœŸè´§å¸‚åœºé£é™©è¾ƒå¤§ï¼Œè¯·è°¨æ…æŠ•èµ„ã€‚
        </div>
        """,
        unsafe_allow_html=True
    )


if __name__ == "__main__":
    main()