import streamlit as st
import pandas as pd
import os
import io
import matplotlib.pyplot as plt
import zipfile
import shutil
from datetime import datetime
import base64
import tempfile
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import seaborn as sns
import numpy as np


def generate_model_id():
    """ç”ŸæˆåŸºäºæ—¥æœŸæ—¶é—´çš„æ¨¡å‹ID"""
    return datetime.now().strftime("%Y%m%d_%H%M%S")


def get_model_files():
    """è·å–æ‰€æœ‰å¯ç”¨çš„æ¨¡å‹æ–‡ä»¶"""
    model_files = []
    models_dir = "../models"
    if os.path.exists(models_dir):
        for file in os.listdir(models_dir):
            if file.endswith('.pkl'):
                model_name = file.replace('.pkl', '')
                model_files.append(model_name)
    return sorted(model_files, reverse=True)  # æœ€æ–°çš„åœ¨å‰


def save_model_with_id(model, task_type, model_info=None):
    """ä¿å­˜æ¨¡å‹å¹¶æ·»åŠ æ—¥æœŸæ—¶é—´ID"""
    model_id = generate_model_id()
    model_name = f"{task_type}_model_{model_id}"
    models_dir = "../models"

    # ç¡®ä¿modelsç›®å½•å­˜åœ¨
    os.makedirs(models_dir, exist_ok=True)

    # ä¿å­˜æ¨¡å‹
    if task_type == "classification":
        from pycaret.classification import save_model as save_clf_model
        save_clf_model(model, f"{models_dir}/{model_name}")
    elif task_type == "regression":
        from pycaret.regression import save_model as save_reg_model
        save_reg_model(model, f"{models_dir}/{model_name}")
    elif task_type == "clustering":
        from pycaret.clustering import save_model as save_cluster_model
        save_cluster_model(model, f"{models_dir}/{model_name}")

    # ä¿å­˜æ¨¡å‹ä¿¡æ¯
    info_path = f"{models_dir}/{model_name}_info.txt"
    with open(info_path, 'w', encoding='utf-8') as f:
        f.write(f"æ¨¡å‹åç§°: {model_name}\n")
        f.write(f"ä»»åŠ¡ç±»å‹: {task_type}\n")
        f.write(f"åˆ›å»ºæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        if model_info:
            for key, value in model_info.items():
                f.write(f"{key}: {value}\n")

    return model_name


def create_clustering_visualizations(data, cluster_labels, n_clusters):
    """åˆ›å»ºèšç±»å¯è§†åŒ–å›¾è¡¨"""
    visualizations = {}

    # è·å–æ•°å€¼å‹åˆ—
    numeric_columns = data.select_dtypes(include=[np.number]).columns.tolist()

    if len(numeric_columns) >= 2:
        # 1. æ•£ç‚¹å›¾ï¼ˆå‰ä¸¤ä¸ªä¸»è¦ç‰¹å¾ï¼‰
        fig1 = px.scatter(
            data,
            x=numeric_columns[0],
            y=numeric_columns[1],
            color=cluster_labels,
            title=f"èšç±»ç»“æœæ•£ç‚¹å›¾ ({numeric_columns[0]} vs {numeric_columns[1]})",
            color_discrete_sequence=px.colors.qualitative.Set3
        )
        visualizations['scatter'] = fig1

    if len(numeric_columns) >= 3:
        # 2. 3Dæ•£ç‚¹å›¾ï¼ˆå‰ä¸‰ä¸ªä¸»è¦ç‰¹å¾ï¼‰
        fig2 = px.scatter_3d(
            data,
            x=numeric_columns[0],
            y=numeric_columns[1],
            z=numeric_columns[2],
            color=cluster_labels,
            title=f"3Dèšç±»ç»“æœ ({numeric_columns[0]} vs {numeric_columns[1]} vs {numeric_columns[2]})",
            color_discrete_sequence=px.colors.qualitative.Set3
        )
        visualizations['scatter_3d'] = fig2

    # 3. èšç±»åˆ†å¸ƒé¥¼å›¾
    cluster_counts = pd.Series(cluster_labels).value_counts().sort_index()
    fig3 = px.pie(
        values=cluster_counts.values,
        names=[f'èšç±» {i}' for i in cluster_counts.index],
        title='å„èšç±»æ ·æœ¬åˆ†å¸ƒ'
    )
    visualizations['pie'] = fig3

    # 4. èšç±»ä¸­å¿ƒçƒ­åŠ›å›¾ï¼ˆå¦‚æœæœ‰è¶³å¤Ÿç‰¹å¾ï¼‰
    if len(numeric_columns) >= 2:
        data_with_clusters = data.copy()
        data_with_clusters['Cluster'] = cluster_labels

        # è®¡ç®—æ¯ä¸ªèšç±»çš„ä¸­å¿ƒç‚¹
        cluster_centers = data_with_clusters.groupby('Cluster')[numeric_columns].mean()

        fig4 = px.imshow(
            cluster_centers.T,
            labels=dict(x="èšç±»", y="ç‰¹å¾", color="å‡å€¼"),
            title="èšç±»ä¸­å¿ƒçƒ­åŠ›å›¾",
            color_continuous_scale='RdYlBu_r'
        )
        visualizations['heatmap'] = fig4

    return visualizations


# K-meansèšç±»ä»»åŠ¡å‡½æ•°
def clustering_task(data, n_clusters, features=None):
    from pycaret.clustering import setup, create_model, assign_model, pull, plot_model
    from pycaret.clustering import save_model as save_cluster_model

    # æ•°æ®é¢„å¤„ç†ï¼šåªé€‰æ‹©æ•°å€¼å‹ç‰¹å¾
    numeric_data = data.select_dtypes(include=[np.number])

    if features:
        # å¦‚æœç”¨æˆ·é€‰æ‹©äº†ç‰¹å®šç‰¹å¾
        available_features = [f for f in features if f in numeric_data.columns]
        if available_features:
            numeric_data = numeric_data[available_features]

    if numeric_data.empty:
        st.error("âŒ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„æ•°å€¼å‹ç‰¹å¾è¿›è¡Œèšç±»åˆ†æ")
        return None, None, None

    # è®¾ç½®èšç±»ç¯å¢ƒ
    setup(data=numeric_data, session_id=123, normalize=True, verbose=False)

    # åˆ›å»ºK-meansæ¨¡å‹
    with st.spinner("æ­£åœ¨è®­ç»ƒK-meansèšç±»æ¨¡å‹..."):
        kmeans_model = create_model('kmeans', num_clusters=n_clusters)

    st.success("âœ… èšç±»æ¨¡å‹è®­ç»ƒå®Œæˆï¼")

    # åˆ†é…èšç±»æ ‡ç­¾
    clustered_data = assign_model(kmeans_model)

    # åˆ›å»ºå¯è§†åŒ–
    visualizations = create_clustering_visualizations(numeric_data, clustered_data['Cluster'], n_clusters)

    # ä¿å­˜æ¨¡å‹ä¿¡æ¯
    model_info = {
        "æ•°æ®é›†å¤§å°": f"{len(data)} è¡Œ",
        "åŸå§‹ç‰¹å¾æ•°é‡": f"{len(data.columns)} ä¸ª",
        "æ•°å€¼ç‰¹å¾æ•°é‡": f"{len(numeric_data.columns)} ä¸ª",
        "èšç±»æ•°é‡": n_clusters,
        "èšç±»ç®—æ³•": "K-means",
        "ä½¿ç”¨çš„ç‰¹å¾": ", ".join(numeric_data.columns.tolist())
    }

    # è®¡ç®—èšç±»ç»Ÿè®¡ä¿¡æ¯
    cluster_stats = clustered_data.groupby('Cluster').agg({
        col: ['mean', 'std', 'count'] for col in numeric_data.columns
    }).round(3)

    model_info["èšç±»ç»Ÿè®¡"] = f"å·²ç”Ÿæˆå„èšç±»çš„ç»Ÿè®¡ä¿¡æ¯"

    # ä½¿ç”¨æ–°çš„ä¿å­˜å‡½æ•°
    model_name = save_model_with_id(kmeans_model, "clustering", model_info)
    st.session_state.current_model_name = model_name

    # ä¿å­˜èšç±»ç»“æœ
    clustered_data.to_csv(f"../models/{model_name}_results.csv", index=False)

    return kmeans_model, clustered_data, model_name, visualizations, cluster_stats


# åˆ†ç±»ä»»åŠ¡å‡½æ•°
def classification_task(data, target_variable, train_size):
    from pycaret.classification import setup, compare_models, save_model, pull, plot_model, predict_model
    from pycaret.classification import save_model as save_clf_model

    setup(data=data, target=target_variable, session_id=123, normalize=True, train_size=train_size)
    best_model = compare_models()
    st.success("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼")

    # ä¿å­˜æ¨¡å‹ä¿¡æ¯
    model_comparison = pull()
    best_model_name = str(best_model)
    accuracy = model_comparison.loc['Accuracy', best_model_name] if 'Accuracy' in model_comparison.index else 'N/A'

    model_info = {
        "æ•°æ®é›†å¤§å°": f"{len(data)} è¡Œ",
        "ç‰¹å¾æ•°é‡": f"{len(data.columns) - 1} ä¸ª",
        "ç›®æ ‡å˜é‡": target_variable,
        "è®­ç»ƒé›†æ¯”ä¾‹": f"{train_size:.1%}",
        "æœ€ä½³æ¨¡å‹": best_model_name,
        "å‡†ç¡®ç‡": f"{accuracy:.4f}" if accuracy != 'N/A' else 'N/A'
    }

    # ä½¿ç”¨æ–°çš„ä¿å­˜å‡½æ•°
    model_name = save_model_with_id(best_model, "classification", model_info)
    st.session_state.current_model_name = model_name

    return best_model, model_comparison, model_name


# å›å½’ä»»åŠ¡å‡½æ•°
def regression_task(data, target_variable, train_size):
    from pycaret.regression import setup, compare_models, save_model, pull, predict_model
    from pycaret.regression import save_model as save_reg_model

    setup(data=data, target=target_variable, train_size=train_size)
    best_model = compare_models()
    st.success("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼")

    # ä¿å­˜æ¨¡å‹ä¿¡æ¯
    model_comparison = pull()
    best_model_name = str(best_model)
    r2 = model_comparison.loc['R2', best_model_name] if 'R2' in model_comparison.index else 'N/A'
    rmse = model_comparison.loc['RMSE', best_model_name] if 'RMSE' in model_comparison.index else 'N/A'

    model_info = {
        "æ•°æ®é›†å¤§å°": f"{len(data)} è¡Œ",
        "ç‰¹å¾æ•°é‡": f"{len(data.columns) - 1} ä¸ª",
        "ç›®æ ‡å˜é‡": target_variable,
        "è®­ç»ƒé›†æ¯”ä¾‹": f"{train_size:.1%}",
        "æœ€ä½³æ¨¡å‹": best_model_name,
        "RÂ² åˆ†æ•°": f"{r2:.4f}" if r2 != 'N/A' else 'N/A',
        "RMSE": f"{rmse:.4f}" if rmse != 'N/A' else 'N/A'
    }

    # ä½¿ç”¨æ–°çš„ä¿å­˜å‡½æ•°
    model_name = save_model_with_id(best_model, "regression", model_info)
    st.session_state.current_model_name = model_name

    return best_model, model_comparison, model_name


# é¢„æµ‹å‡½æ•°
def prediction(model_path, prediction_file):
    try:
        models_dir = "../models"
        full_model_path = f"{models_dir}/{model_path}"

        if os.path.exists(f'{full_model_path}.pkl'):
            if 'classification' in model_path:
                from pycaret.classification import load_model, predict_model
            elif 'regression' in model_path:
                from pycaret.regression import load_model, predict_model
            elif 'clustering' in model_path:
                from pycaret.clustering import load_model, assign_model
                # èšç±»ä»»åŠ¡çš„ç‰¹æ®Šå¤„ç†
                loaded_model = load_model(full_model_path)
                st.success("âœ… èšç±»æ¨¡å‹å·²æˆåŠŸè½½å…¥")

                # è¯»å–å¾…é¢„æµ‹æ•°æ®
                if prediction_file.name.endswith('.csv'):
                    prediction_data = pd.read_csv(prediction_file, encoding='utf-8-sig')
                elif prediction_file.name.endswith('.xlsx'):
                    prediction_data = pd.read_excel(prediction_file, engine='openpyxl')

                # åªä¿ç•™æ•°å€¼å‹ç‰¹å¾
                numeric_prediction_data = prediction_data.select_dtypes(include=[np.number])

                # è¿›è¡Œèšç±»é¢„æµ‹
                clustered_prediction = assign_model(loaded_model, data=numeric_prediction_data)
                st.success("âœ… èšç±»é¢„æµ‹å®Œæˆï¼")
                st.write("èšç±»ç»“æœï¼š")
                st.dataframe(clustered_prediction)

                # æä¾›ä¸‹è½½åŠŸèƒ½
                csv = clustered_prediction.to_csv(index=False)
                st.download_button(
                    label="ä¸‹è½½èšç±»ç»“æœ (CSV)",
                    data=csv,
                    file_name=f"clustering_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv"
                )
                return

            # åˆ†ç±»å’Œå›å½’ä»»åŠ¡çš„é€šç”¨å¤„ç†
            loaded_model = load_model(full_model_path)
            st.success("âœ… æ¨¡å‹å·²æˆåŠŸè½½å…¥")

            # è¯»å–å¾…é¢„æµ‹æ•°æ®
            if prediction_file.name.endswith('.csv'):
                prediction_data = pd.read_csv(prediction_file, encoding='utf-8-sig')
            elif prediction_file.name.endswith('.xlsx'):
                prediction_data = pd.read_excel(prediction_file, engine='openpyxl')

            predictions = predict_model(loaded_model, data=prediction_data)
            st.success("âœ… é¢„æµ‹å®Œæˆï¼")
            st.write("é¢„æµ‹ç»“æœï¼š")
            st.dataframe(predictions)

            # æä¾›ä¸‹è½½åŠŸèƒ½
            csv = predictions.to_csv(index=False)
            st.download_button(
                label="ä¸‹è½½é¢„æµ‹ç»“æœ (CSV)",
                data=csv,
                file_name=f"predictions_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv"
            )

        else:
            st.error("âŒ æœªæ‰¾åˆ°ç›¸åº”çš„æ¨¡å‹æ–‡ä»¶ï¼Œè¯·å…ˆè®­ç»ƒæ¨¡å‹æˆ–é€‰æ‹©æ­£ç¡®çš„æ¨¡å‹")
    except Exception as e:
        st.error(f"âŒ é¢„æµ‹è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")


def export_model(model_name):
    """å¯¼å‡ºæ¨¡å‹æ–‡ä»¶"""
    try:
        models_dir = "../models"
        model_path = f"{models_dir}/{model_name}"

        # åˆ›å»ºä¸´æ—¶ç›®å½•
        with tempfile.TemporaryDirectory() as temp_dir:
            # å¤åˆ¶æ¨¡å‹æ–‡ä»¶
            shutil.copy(f"{model_path}.pkl", temp_dir)

            # å¤åˆ¶æ¨¡å‹ä¿¡æ¯æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            info_file = f"{model_path}_info.txt"
            if os.path.exists(info_file):
                shutil.copy(info_file, temp_dir)

            # å¤åˆ¶èšç±»ç»“æœæ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            results_file = f"{model_path}_results.csv"
            if os.path.exists(results_file):
                shutil.copy(results_file, temp_dir)

            # åˆ›å»ºzipæ–‡ä»¶
            zip_path = f"{temp_dir}/{model_name}.zip"
            with zipfile.ZipFile(zip_path, 'w') as zipf:
                zipf.write(f"{temp_dir}/{model_name}.pkl", f"{model_name}.pkl")
                if os.path.exists(info_file):
                    zipf.write(f"{temp_dir}/{model_name}_info.txt", f"{model_name}_info.txt")
                if os.path.exists(results_file):
                    zipf.write(f"{temp_dir}/{model_name}_results.csv", f"{model_name}_results.csv")

            # è¯»å–zipæ–‡ä»¶å¹¶è¿”å›
            with open(zip_path, 'rb') as f:
                zip_data = f.read()

            return zip_data
    except Exception as e:
        st.error(f"å¯¼å‡ºæ¨¡å‹æ—¶å‡ºç°é”™è¯¯: {str(e)}")
        return None


def import_model(uploaded_file):
    """å¯¼å…¥æ¨¡å‹æ–‡ä»¶"""
    try:
        models_dir = "../models"
        os.makedirs(models_dir, exist_ok=True)

        # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
        temp_path = f"temp_model_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip"
        with open(temp_path, "wb") as f:
            f.write(uploaded_file.getvalue())

        # è§£å‹æ–‡ä»¶
        with zipfile.ZipFile(temp_path, 'r') as zipf:
            zipf.extractall(models_dir)

        # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
        os.remove(temp_path)

        st.success("âœ… æ¨¡å‹å¯¼å…¥æˆåŠŸï¼")
        return True
    except Exception as e:
        st.error(f"å¯¼å…¥æ¨¡å‹æ—¶å‡ºç°é”™è¯¯: {str(e)}")
        return False


def show_model_info(model_name):
    """æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯"""
    try:
        models_dir = "../models"
        info_file = f"{models_dir}/{model_name}_info.txt"

        if os.path.exists(info_file):
            with open(info_file, 'r', encoding='utf-8') as f:
                info = f.read()
            st.info(f"ğŸ“‹ **æ¨¡å‹ä¿¡æ¯**\n\n```\n{info}\n```")
        else:
            st.info("ğŸ“‹ æ¨¡å‹ä¿¡æ¯æ–‡ä»¶ä¸å­˜åœ¨")
    except Exception as e:
        st.warning(f"è¯»å–æ¨¡å‹ä¿¡æ¯æ—¶å‡ºç°é”™è¯¯: {str(e)}")


# å®šä¹‰ä¸»å‡½æ•°
def main():
    st.title("MLquick - æœºå™¨å­¦ä¹ é›¶ä»£ç åº”ç”¨å¹³å°")

    # ä¾§è¾¹æ  - æ¨¡å‹ç®¡ç†
    st.sidebar.markdown("## ğŸ”§ æ¨¡å‹ç®¡ç†")

    # æ˜¾ç¤ºå½“å‰æ¨¡å‹
    if 'current_model_name' in st.session_state and st.session_state.current_model_name:
        st.sidebar.success(f"å½“å‰æ¨¡å‹: {st.session_state.current_model_name}")
        show_model_info(st.session_state.current_model_name)

    # æ¨¡å‹å¯¼å‡º
    if 'current_model_name' in st.session_state and st.session_state.current_model_name:
        if st.sidebar.button("ğŸ“¤ å¯¼å‡ºå½“å‰æ¨¡å‹"):
            zip_data = export_model(st.session_state.current_model_name)
            if zip_data:
                st.sidebar.download_button(
                    label=f"ä¸‹è½½ {st.session_state.current_model_name}",
                    data=zip_data,
                    file_name=f"{st.session_state.current_model_name}.zip",
                    mime="application/zip"
                )

    # æ¨¡å‹å¯¼å…¥
    st.sidebar.markdown("---")
    st.sidebar.markdown("### ğŸ“¥ å¯¼å…¥æ¨¡å‹")
    uploaded_model = st.sidebar.file_uploader("ä¸Šä¼ æ¨¡å‹æ–‡ä»¶ (.zip)", type=["zip"])
    if uploaded_model is not None:
        if st.sidebar.button("å¯¼å…¥æ¨¡å‹"):
            if import_model(uploaded_model):
                st.rerun()

    # å¯ç”¨æ¨¡å‹åˆ—è¡¨
    st.sidebar.markdown("---")
    st.sidebar.markdown("### ğŸ“‚ å¯ç”¨æ¨¡å‹")
    model_files = get_model_files()
    if model_files:
        selected_model = st.sidebar.selectbox("é€‰æ‹©æ¨¡å‹", model_files)
        if st.sidebar.button("åŠ è½½é€‰ä¸­æ¨¡å‹"):
            st.session_state.current_model_name = selected_model
            st.rerun()
    else:
        st.sidebar.info("æš‚æ— å¯ç”¨æ¨¡å‹")

    # ä¸»ç•Œé¢
    st.markdown("---")

    # ä¸Šä¼ æ•°æ®
    uploaded_file = st.file_uploader("ğŸ“ ä¸Šä¼ æ•°æ®é›† (CSV æˆ– Excelæ ¼å¼)", type=["csv", "xlsx"])

    if uploaded_file is not None:
        # åˆ¤æ–­æ–‡ä»¶ç±»å‹å¹¶è¯»å–æ•°æ®
        if uploaded_file.name.endswith('.csv'):
            data = pd.read_csv(uploaded_file, encoding='utf-8-sig')
        elif uploaded_file.name.endswith('.xlsx'):
            data = pd.read_excel(uploaded_file, engine='openpyxl')

        data = pd.DataFrame(data)
        st.markdown("### ğŸ“Š æ•°æ®é¢„è§ˆ")
        st.write(f"æ•°æ®å½¢çŠ¶: {data.shape[0]} è¡Œ Ã— {data.shape[1]} åˆ—")
        st.dataframe(data.head(10))

        # æ•°æ®åŸºæœ¬ä¿¡æ¯
        numeric_columns = data.select_dtypes(include=[np.number]).columns.tolist()
        st.info(f"ğŸ“ˆ **æ•°æ®ç»Ÿè®¡**: æ•°å€¼å‹ç‰¹å¾ {len(numeric_columns)} ä¸ªï¼Œæ€»ç‰¹å¾ {len(data.columns)} ä¸ª")

        # é€‰æ‹©ä»»åŠ¡ç±»å‹
        st.markdown("### âš™ï¸ æ¨¡å‹é…ç½®")
        task_type = st.selectbox("é€‰æ‹©ä»»åŠ¡ç±»å‹", ["åˆ†ç±»", "å›å½’", "èšç±»"])

        if task_type == "èšç±»":
            # èšç±»ä»»åŠ¡ç‰¹æ®Šé…ç½®
            st.markdown("#### ğŸ¯ èšç±»é…ç½®")

            # èšç±»æ•°é‡
            n_clusters = st.number_input(
                "èšç±»æ•°é‡ (Kå€¼)",
                min_value=2,
                max_value=min(20, len(data)),
                value=3,
                step=1,
                help="K-meansèšç±»çš„ç±»åˆ«æ•°é‡"
            )

            # ç‰¹å¾é€‰æ‹©
            if numeric_columns:
                selected_features = st.multiselect(
                    "é€‰æ‹©ç”¨äºèšç±»çš„ç‰¹å¾ (ç•™ç©ºåˆ™ä½¿ç”¨æ‰€æœ‰æ•°å€¼ç‰¹å¾)",
                    numeric_columns,
                    default=numeric_columns[:min(5, len(numeric_columns))],  # é»˜è®¤é€‰æ‹©å‰5ä¸ªç‰¹å¾
                    help="é€‰æ‹©ç”¨äºèšç±»åˆ†æçš„æ•°å€¼å‹ç‰¹å¾"
                )
            else:
                st.warning("âš ï¸ æ•°æ®ä¸­æ²¡æœ‰æ•°å€¼å‹ç‰¹å¾ï¼Œæ— æ³•è¿›è¡Œèšç±»åˆ†æ")
                selected_features = []

        else:
            # åˆ†ç±»å’Œå›å½’ä»»åŠ¡çš„é…ç½®
            target_variable = st.selectbox("é€‰æ‹©ç›®æ ‡å˜é‡", data.columns)
            train_size = st.number_input("è¾“å…¥è®­ç»ƒé›†æ¯”ä¾‹ï¼ˆ0 - 1ä¹‹é—´ï¼‰", min_value=0.0, max_value=1.0, value=0.7, step=0.01)

        # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
        if 'best_model' not in st.session_state:
            st.session_state.best_model = None
        if 'model_comparison' not in st.session_state:
            st.session_state.model_comparison = None
        if 'clustered_data' not in st.session_state:
            st.session_state.clustered_data = None
        if 'visualizations' not in st.session_state:
            st.session_state.visualizations = None

        # è®­ç»ƒæ¨¡å‹
        if st.button("ğŸš€ å¼€å§‹è®­ç»ƒæ¨¡å‹", type="primary"):
            with st.spinner("æ­£åœ¨è®­ç»ƒæ¨¡å‹ï¼Œè¯·ç¨å€™..."):
                if task_type == "èšç±»":
                    if not numeric_columns:
                        st.error("âŒ æ²¡æœ‰æ•°å€¼å‹ç‰¹å¾å¯ç”¨äºèšç±»åˆ†æ")
                    else:
                        model, clustered_data, model_name, visualizations, cluster_stats = clustering_task(
                            data, n_clusters, selected_features)
                        if model is not None:
                            st.session_state.best_model = model
                            st.session_state.clustered_data = clustered_data
                            st.session_state.visualizations = visualizations
                            st.session_state.cluster_stats = cluster_stats

                elif task_type == "åˆ†ç±»":
                    st.session_state.best_model, st.session_state.model_comparison, model_name = classification_task(
                        data, target_variable, train_size)
                else:  # å›å½’
                    st.session_state.best_model, st.session_state.model_comparison, model_name = regression_task(
                        data, target_variable, train_size)

        # æ˜¾ç¤ºç»“æœ
        if task_type == "èšç±»" and st.session_state.clustered_data is not None:
            st.markdown("### ğŸ“ˆ èšç±»åˆ†æç»“æœ")

            # æ˜¾ç¤ºèšç±»ç»Ÿè®¡ä¿¡æ¯
            if 'cluster_stats' in st.session_state:
                st.markdown("#### ğŸ“Š èšç±»ç»Ÿè®¡ä¿¡æ¯")
                st.dataframe(st.session_state.cluster_stats)

            # æ˜¾ç¤ºå¯è§†åŒ–
            if st.session_state.visualizations:
                st.markdown("#### ğŸ¨ èšç±»å¯è§†åŒ–")

                # æ•£ç‚¹å›¾
                if 'scatter' in st.session_state.visualizations:
                    st.plotly_chart(st.session_state.visualizations['scatter'], use_container_width=True)

                # 3Dæ•£ç‚¹å›¾
                if 'scatter_3d' in st.session_state.visualizations:
                    st.plotly_chart(st.session_state.visualizations['scatter_3d'], use_container_width=True)

                # é¥¼å›¾
                if 'pie' in st.session_state.visualizations:
                    col1, col2 = st.columns(2)
                    with col1:
                        st.plotly_chart(st.session_state.visualizations['pie'], use_container_width=True)

                # çƒ­åŠ›å›¾
                if 'heatmap' in st.session_state.visualizations:
                    with col2:
                        st.plotly_chart(st.session_state.visualizations['heatmap'], use_container_width=True)

            # ä¸‹è½½èšç±»ç»“æœ
            csv = st.session_state.clustered_data.to_csv(index=False)
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½èšç±»ç»“æœ (CSV)",
                data=csv,
                file_name=f"clustering_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv"
            )

        elif task_type != "èšç±»" and st.session_state.model_comparison is not None:
            st.markdown("### ğŸ“ˆ æ¨¡å‹æ€§èƒ½å¯¹æ¯”")
            st.dataframe(st.session_state.model_comparison)

        # é¢„æµ‹åŠŸèƒ½
        st.markdown("---")
        st.markdown("### ğŸ”® æ¨¡å‹é¢„æµ‹")

        # é€‰æ‹©é¢„æµ‹æ–¹å¼
        prediction_mode = st.radio("é€‰æ‹©é¢„æµ‹æ–¹å¼", ["ä½¿ç”¨å½“å‰è®­ç»ƒçš„æ¨¡å‹", "é€‰æ‹©å·²æœ‰æ¨¡å‹"])

        if prediction_mode == "ä½¿ç”¨å½“å‰è®­ç»ƒçš„æ¨¡å‹":
            if 'current_model_name' in st.session_state and st.session_state.current_model_name:
                st.info(f"ä½¿ç”¨æ¨¡å‹: {st.session_state.current_model_name}")
                prediction_file = st.file_uploader("ğŸ“ ä¸Šä¼ å¾…é¢„æµ‹æ•°æ®", type=["csv", "xlsx"], key="pred_current")
                if prediction_file is not None:
                    prediction(st.session_state.current_model_name, prediction_file)
            else:
                st.warning("è¯·å…ˆè®­ç»ƒæ¨¡å‹")

        else:  # é€‰æ‹©å·²æœ‰æ¨¡å‹
            model_files = get_model_files()
            if model_files:
                selected_model = st.selectbox("é€‰æ‹©æ¨¡å‹", model_files, key="pred_model_select")
                st.info(f"ä½¿ç”¨æ¨¡å‹: {selected_model}")
                prediction_file = st.file_uploader("ğŸ“ ä¸Šä¼ å¾…é¢„æµ‹æ•°æ®", type=["csv", "xlsx"], key="pred_existing")
                if prediction_file is not None:
                    prediction(selected_model, prediction_file)
            else:
                st.warning("æš‚æ— å¯ç”¨æ¨¡å‹ï¼Œè¯·å…ˆè®­ç»ƒæ¨¡å‹æˆ–å¯¼å…¥æ¨¡å‹")

    # é¡µè„š
    st.markdown("---")
    st.markdown("### ğŸ’¡ ä½¿ç”¨æç¤º")
    st.markdown("""
    - **åˆ†ç±»ä»»åŠ¡**: éœ€è¦é€‰æ‹©ç›®æ ‡å˜é‡ï¼Œç”¨äºé¢„æµ‹ç±»åˆ«
    - **å›å½’ä»»åŠ¡**: éœ€è¦é€‰æ‹©ç›®æ ‡å˜é‡ï¼Œç”¨äºé¢„æµ‹æ•°å€¼
    - **èšç±»ä»»åŠ¡**: è‡ªåŠ¨å‘ç°æ•°æ®ä¸­çš„ç¾¤ç»„ï¼Œæ— éœ€ç›®æ ‡å˜é‡
    - æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: CSV (.csv), Excel (.xlsx)
    - æ¨¡å‹ä¼šè‡ªåŠ¨ä¿å­˜ï¼Œä¸ä¼šè¦†ç›–ä¹‹å‰çš„æ¨¡å‹
    - å¯ä»¥é€šè¿‡ä¾§è¾¹æ å¯¼å…¥/å¯¼å‡ºæ¨¡å‹
    - é¢„æµ‹ç»“æœå¯ä»¥ä¸‹è½½ä¸ºCSVæ–‡ä»¶
    - å»ºè®®è®­ç»ƒé›†æ¯”ä¾‹è®¾ç½®åœ¨0.6-0.8ä¹‹é—´ï¼ˆä»…å¯¹åˆ†ç±»å’Œå›å½’ä»»åŠ¡ï¼‰
    """)


if __name__ == "__main__":
    main()